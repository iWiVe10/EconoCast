import pandas as pd
import numpy as np
from econocast.ml_logic.data import load_data, save_data_preprocess, load_data_preprocess
from econocast.ml_logic.preprocessor import preprocess_data, clean_data
from econocast.ml_logic.model import train_model, evaluate_model, predict_model, create_sequences
from econocast.ml_logic.registry import save_model, load_model
from econocast.params import *

# ===============================
# Preprocesamiento de Datos
# ===============================
def preprocess():
    """Carga y preprocesa el dataset."""
    print("\nğŸš€â­ï¸ Iniciando Preprocesamiento de Datos")

    # Cargar data cruda
    df = load_data()

    # Limpieza de data (no estaba antes)
    df = clean_data(df)

    # Preprocesamiento de data
    df_scaled, scaler = preprocess_data(df)

    # Guarda el procesamiento
    save_data_preprocess(df_scaled, scaler)

    print("\nâœ…ğŸ“¦ Preprocesamiento completado y guardado")

    return df_scaled, scaler

# ===============================
# Entrenamiento del Modelo
# ===============================
def train():
    """Entrena un modelo de ARIMA para series temporales."""
    print("\nğŸš€â­ï¸ Iniciando Entrenamiento")

    # Cargando data preprocesada
    df_scaled, scaler = load_data_preprocess()

    # Creando secuencia
    X, y = create_sequences(df_scaled, seq_length=18)

    train_size = int(len(X) * 0.8)
    X_train, X_test, y_train, y_test = X[:train_size], X[train_size:], y[:train_size], y[train_size:]

    # Entrenando modelo
    model = train_model(X_train, y_train, X_test, y_test)

    # Guardando modelo entrenado
    model_name = 'RNN_model'
    save_model(model, scaler, model_name)

    print("âœ…ğŸ“¦ Modelo entrenado y guardado")

    return model


# ===============================
# EvaluaciÃ³n del Modelo
# ===============================
def evaluate():
    """EvalÃºa el modelo ARIMA entrenado con datos de validaciÃ³n."""
    print("\nğŸ“Šâ­ï¸ Iniciando Evaluacion")
    # Cargar modelo
    model, _ = load_model('RNN_model')

    # Cargar data escalada
    df_scaled, scaler = load_data_preprocess()

    # Crear secuencia
    X, y = create_sequences(df_scaled, seq_length=18)

    train_size = int(len(X) * 0.8)
    X_test, y_test = X[train_size:], y[train_size:]

    loss, mae, mse = evaluate_model(model, X_test, y_test )

    # Mostrar resultados
    print(f"\nâœ…ğŸ“‰ EvaluaciÃ³n completada.")
    print(f"ğŸ“Œ LOSS  (Perdida): {loss:.4f}")
    print(f"ğŸ“Œ MAE  (Error Absoluto Medio): {mae:.4f}")
    print(f"ğŸ“Œ RMSE (Error CuadrÃ¡tico Medio): {mse:.4f}")

    return loss, mae, mse



# ===============================
# PredicciÃ³n con ARIMA
# ===============================
def pred():
    """
    Genera predicciones usando el modelo ARIMA entrenado.
    """

    print("\nâ­ï¸ Iniciando prediccion")

    model, _ = load_model('RNN_model')
    df_scaled, escalado = load_data_preprocess()
    sample = df_scaled.iloc[-18:].values.reshape(1, 18, -1)
    prediction = predict_model(model, sample)
    print(f"ğŸ”¹ PredicciÃ³n Normalizada: {prediction[0][0]}")  # DepuraciÃ³n
    if _:
        descaled_prediction = _.inverse_transform(np.array(prediction).reshape(-1, 1))[0, 0]
        print(f"ğŸ”¹ PredicciÃ³n Desescalada: {descaled_prediction}")  # DepuraciÃ³n

        return {"valor": float(descaled_prediction)}
    return {"valor": float(prediction[0][0])}



if __name__ == '__main__':
    preprocess()
    train()
    evaluate()
    pred()
